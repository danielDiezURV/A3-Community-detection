{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A3. Community detection\n",
    "\n",
    "The objective of this activity is to understand how community detection algorithms work and some of the recurrent nuances appearing when using these tools to characterize the mesoscale of complex networks. The activity is divided into two different tasks.\n",
    "\n",
    "**Characterization of the community structure of networks with block structure**\n",
    "In this part of the activity, you will use community detection algorithms to analyze the community structure of networks generated according to the stochastic block model (SBM). The parameters characterizing the networks are:\n",
    "\n",
    "+ N: number of nodes. For all the networks, N=300.\n",
    "+ nblocks: number of different blocks (types) of nodes. For all the networks, nblocks=5\n",
    "+ prs: Probability that a node (belonging to a given block) establishes a link with another node from a different block. For all networks here studied, prs=0.02\n",
    "+ prr: Probability that a single node (belonging to a given block) establishes a link with another node from the same block. This indicator varies across networks, being its value indicated in each filename. For example, for the synthetic network in file ‘synthetic_network_N_300_blocks_5_prr_0.04_prs_0.02.net’, prr=0.04. \n",
    "\n",
    "You should use at least three algorithms to find the community structure of the different networks provided in the dataset, i.e., as prr varies from prr=0 (no connections inside each block) to prr=1 (all-to-all interactions inside blocks). Out of these three algorithms, one should be Infomap whereas the other two should be modularity maximization algorithms, e.g., Girvan-Newman, Agglomerative Greedy algorithm, Louvain, Leiden, etc. Note that, for all the synthetic networks, the ‘true’ group structure is known. Namely, the first 60 nodes (labeled as 1, 2, 3, …,60) are contained in group 1, the next 60 (labeled 60, 62, ..., 120) in group 2, and so on. \n",
    "\n",
    "The report must include:\n",
    "\n",
    "+ Evolution of the number of communities and the modularity of the partitions found by each algorithm as a function of prr. You should also compare the partition found by each algorithm with the ‘true’ partition using at least the following standard measures: Jaccard Index, Normalized Mutual Information (arithmetic normalization), and Normalized Variation of Information. It is not necessary to implement the calculation of these indices, you may use any program. Beware that you may find implementations of the Jaccard Index that are not related to community detection, thus the results would be incorrect.\n",
    "+ A color-coded visualization of the community structure of the network for prr=0.02, prr=0.16, and prr=1.00. To facilitate the comparison of partitions, you should set the position of the nodes in the network by applying any of the algorithms available for representation (e.g., Kamada-Kawai, ForceAtlas, Fruchterman-Reingold, etc.) to the network with prr=1.00. The positions obtained for each node should be kept when representing the other two networks. In each network, the node's color should identify the community assigned by each community detection algorithm. \n",
    "The network layout obtained should resemble this one:\n",
    "\n",
    "\n",
    "![SBM Image](resources/sbm.png)\n",
    "\n",
    "\n",
    "+ A brief discussion on the limitations of the use of modularity to classify whether a network has community structure or not. For instance, from your results, can we state that a network with Q=0.4 has community structure? Why?\n",
    "+ A brief discussion of the differences observed across algorithms. Are the communities detected by both of them equal? Are the modularity values obtained equal? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from cdlib.algorithms import infomap\n",
    "from CommunityDetectionFunctions import CommunityDetectionFunctions\n",
    "\n",
    "with open('results/community_detection_results.csv', 'w') as community_detection_results:\n",
    "    result_data = pd.DataFrame(columns=['Method', 'File', 'Num Communities', 'Modularity', 'Jaccard Index', 'Normalized Mutual Information', 'Normalized Variation of Information'])\n",
    "\n",
    "    directory = 'A3_synthetic_networks'\n",
    "    known_community_file = 'synthetic_network_N_300_blocks_5_prr_1.00_prs_0.02.net'\n",
    "    file_path = os.path.join(directory, known_community_file)\n",
    "    known_community_graph = nx.Graph(nx.read_pajek(file_path))\n",
    "    known_communities = [list(known_community_graph.nodes)[i:i+60] for i in range(0, len(known_community_graph.nodes), 60)]\n",
    "\n",
    "    cd_functions = CommunityDetectionFunctions()\n",
    "    cd_functions.set_kamada_kawai_layout(known_community_graph)\n",
    "    cd_functions.plot_kamada_kawai_communities(known_community_graph, known_communities, 'Known_communities', known_community_file)\n",
    "    \n",
    "\n",
    "    for file in [file for file in os.listdir(directory) if file.endswith('.net')]:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        graph = nx.Graph(nx.read_pajek(file_path))\n",
    "\n",
    "        # Agglomerative greedy algorithm\n",
    "        communities = nx.algorithms.community.greedy_modularity_communities(graph)\n",
    "\n",
    "        result_data.loc[len(result_data.index)] = cd_functions.evaluate_communities(graph, known_communities, communities, 'Agglomerative', file)\n",
    "        cd_functions.plot_kamada_kawai_communities(graph, communities, 'Agglomerative', file)\n",
    "\n",
    "        # Louvain\n",
    "        communities = nx.algorithms.community.louvain_communities(graph)\n",
    "        result_data.loc[len(result_data.index)] = cd_functions.evaluate_communities(graph, known_communities, communities, 'Louvain', file)\n",
    "        cd_functions.plot_kamada_kawai_communities(graph, communities, 'Louvain', file)\n",
    "\n",
    "        # InfoMap\n",
    "        communities = infomap(graph).communities\n",
    "        result_data.loc[len(result_data.index)] = cd_functions.evaluate_communities(graph, known_communities, communities, 'InfoMap', file)\n",
    "        cd_functions.plot_kamada_kawai_communities(graph, communities, 'InfoMap', file)\n",
    "\n",
    "            \n",
    "            \n",
    "    result_data.to_csv(community_detection_results, index=False, header=True, sep=\";\", decimal=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Characterization of the community structure of real networks**\n",
    "\n",
    "In this part of the activity, you should use algorithms relying on modularity maximization to analyze the community structure of a real network capturing face-to-face interactions in a primary school in France. In this network, nodes represent either students or teachers and weights are proportional to the time they were together during the two days in which interactions were measured. More information on the network can be found here: \n",
    "\n",
    "http://www.sociopatterns.org/publications/high-resolution-measurements-of-face-to-face-contact-patterns-in-a-primary-school/\n",
    "\n",
    "You should analyze both the unweighted (‘primaryschool_u.net’) and the weighted (‘primaryschool_w.net’) versions of this network. In addition, node metadata is available (metadata_primary_school.txt), indicating the school group each individual belongs to.\n",
    "\n",
    "The report must include:\n",
    "\n",
    "+ A comparison between the community structure found in both the unweighted and the weighted networks. Use a color-coded representation, similar to the one explained in the previous activity. The position of the nodes should be set by applying the chosen positioning algorithm to the weighted network. Warning: If you choose the Kamada-Kawai layout algorithm, the weights introduced in the algorithm should be the inverse (1/wij) of the actual weights (wij) of the network.\n",
    "+ The composition of the detected communities in terms of the school groups to which their individuals belong. You should provide a visual representation (e.g. a stacked bar plot, a pie chart) to show how many individuals of each school group are in each community.\n",
    "A brief discussion on the differences among the communities detected in the weighted and unweighted network. Why weights are relevant?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'wurlitzer', 'graph_tool', 'bayanpy'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'wurlitzer'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'known_communities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m cd_functions \u001b[38;5;241m=\u001b[39m CommunityDetectionFunctions()\n\u001b[0;32m     13\u001b[0m cd_functions\u001b[38;5;241m.\u001b[39mset_kamada_kawai_layout(known_community_graph)\n\u001b[1;32m---> 14\u001b[0m cd_functions\u001b[38;5;241m.\u001b[39mplot_kamada_kawai_communities(known_community_graph, \u001b[43mknown_communities\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKnown_communities\u001b[39m\u001b[38;5;124m'\u001b[39m, known_community_file)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(directory) \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.net\u001b[39m\u001b[38;5;124m'\u001b[39m)]:\n\u001b[0;32m     18\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'known_communities' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from cdlib.algorithms import infomap\n",
    "from CommunityDetectionFunctions import CommunityDetectionFunctions\n",
    "\n",
    "directory = 'A3_primary_school_network'\n",
    "known_community_file = 'metadata_primary_school.txt'\n",
    "file_path = os.path.join(directory, known_community_file)\n",
    "known_community_graph = nx.Graph(nx.read_pajek(file_path)) \n",
    "\n",
    "cd_functions = CommunityDetectionFunctions()\n",
    "cd_functions.set(known_community_graph)\n",
    "cd_functions.plot_kamada_kawai_communities(known_community_graph, known_communities, 'Known_communities', known_community_file)\n",
    "\n",
    "\n",
    "for file in [file for file in os.listdir(directory) if file.endswith('.net')]:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    graph = nx.Graph(nx.read_pajek(file_path))\n",
    "\n",
    "    # Agglomerative greedy algorithm\n",
    "    communities = nx.algorithms.community.greedy_modularity_communities(graph)\n",
    "\n",
    "    result_data.loc[len(result_data.index)] = cd_functions.evaluate_communities(graph, known_communities, communities, 'Agglomerative', file)\n",
    "    cd_functions.plot_kamada_kawai_communities(graph, communities, 'Agglomerative', file)\n",
    "\n",
    "    # Louvain\n",
    "    communities = nx.algorithms.community.louvain_communities(graph)\n",
    "    result_data.loc[len(result_data.index)] = cd_functions.evaluate_communities(graph, known_communities, communities, 'Louvain', file)\n",
    "    cd_functions.plot_kamada_kawai_communities(graph, communities, 'Louvain', file)\n",
    "\n",
    "    # InfoMap\n",
    "    communities = infomap(graph).communities\n",
    "    result_data.loc[len(result_data.index)] = cd_functions.evaluate_communities(graph, known_communities, communities, 'InfoMap', file)\n",
    "    cd_functions.plot_kamada_kawai_communities(graph, communities, 'InfoMap', file)\n",
    "\n",
    "            \n",
    "            \n",
    "    result_data.to_csv(community_detection_results, index=False, header=True, sep=\";\", decimal=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
